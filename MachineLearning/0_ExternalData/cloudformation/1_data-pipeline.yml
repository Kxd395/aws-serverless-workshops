AWSTemplateFormatVersion: 2010-09-09
Description: Wild Rydes machine learning infrastructure
Resources:
  DataBucket:
    Type: AWS::S3::Bucket
    DependsOn: IngestUnicornRawDataFunction
    Properties:
      BucketName: !Sub "${AWS::StackName}-databucket-${AWS::AccountId}"
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
      NotificationConfiguration:
        LambdaConfigurations:
          -
            Function: !GetAtt IngestUnicornRawDataFunction.Arn
            Event: "s3:ObjectCreated:*"
            Filter:
              S3Key:
                Rules:
                  -
                    Name: prefix
                    Value: raw/
                  -
                    Name: suffix
                    Value: json
  S3DataBucketInvokeLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref IngestUnicornRawDataFunction
      Principal: s3.amazonaws.com
      SourceArn: !Sub "arn:aws:s3:::${AWS::StackName}-databucket-${AWS::AccountId}"
  DataProcessingExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        -
          PolicyName: "AllowLambdaFunctionality"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "*"
                Resource:
                  -
                    !Sub "arn:aws:s3:::${AWS::StackName}-databucket-${AWS::AccountId}/*"
                  - 
                    !Sub "arn:aws:s3:::${AWS::StackName}-databucket-${AWS::AccountId}"
                  -
                    !GetAtt TransformedAndMappedDataQueue.Arn
                  -
                    !GetAtt TransformAndMapDataFunctionDLQ.Arn
                  -
                    !GetAtt IngestUnicornRawDataFunctionDLQ.Arn
                  -
                    !GetAtt WriteTransformedDataToS3FunctionDLQ.Arn
                  - 
                    !GetAtt IngestedRawDataQueue.Arn
                  -
                    !GetAtt TransformAndMapDataFunctionDLQ.Arn
                  -
                    !GetAtt IngestUnicornRawDataFunctionDLQ.Arn
                  -
                    !GetAtt WriteTransformedDataToS3FunctionDLQ.Arn
        - PolicyName: "AllowLogging"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action: ['logs:*']
                Resource: 'arn:aws:logs:*:*:*'
  TransformAndMapDataFunctionDLQ:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  IngestUnicornRawDataFunctionDLQ:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  WriteTransformedDataToS3FunctionDLQ:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  IngestedRawDataQueue:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  TransformedAndMappedDataQueue:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning

  IngestUnicornRawDataFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import boto3
          import json
          import os

          client = boto3.client('s3')
          sqs = boto3.client('sqs')
          queue_url = os.environ['OUTPUT_QUEUE']

          def send_to_sqs(json_data):
            data = json_data
            if 'travel_data' in json_data:
              data = json_data['travel_data']

            for entry in data:
              lower_cased = {k.lower(): v for k, v in entry.items()}
              response = sqs.send_message(
                QueueUrl=queue_url,
                DelaySeconds=0,
                MessageBody=json.dumps(lower_cased)
              )
            print('all rows sent to sqs')

          def handler(event, context):
              for record in event['Records']:
                  bucket = record['s3']['bucket']['name']
                  key = record['s3']['object']['key']
                  content_object = client.get_object(Bucket=bucket, Key=key)
              file_content = content_object['Body'].read().decode('utf-8')
              json_content = json.loads(file_content)
              send_to_sqs(json_content)

      Description: Wild Rydes lambda function to parse unicorn JSON data and send downstream to lookup nearest groundstation
      Handler: index.handler
      DeadLetterConfig:
        TargetArn: !GetAtt IngestUnicornRawDataFunctionDLQ.Arn
      MemorySize: 256
      Environment:
        Variables:
          OUTPUT_QUEUE: !Ref IngestedRawDataQueue
      Role: !GetAtt DataProcessingExecutionRole.Arn
      Runtime: python3.7
      Timeout: 900
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  TransformAndMapDataFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          from math import cos, asin, sqrt
          import boto3
          import json
          import os

          sqs = boto3.client('sqs')
          queue_url = os.environ['OUTPUT_QUEUE']

          def handler(event, context):
              print('## EVENT')
              print(event)
              for record in event['Records']:
                  json_event = json.loads(record['body'])
                  json_event = event_format_check(json_event)
                  json_event["groundstation"] = closest(groundstations(),
                                                      {"latitude": json_event["latitude"], "longitude": json_event["longitude" ]})["id"]
                  json_event = label_heavy_magic_utilization(json_event)
                  send_message_sqs(json_event)
              return event

          def label_heavy_magic_utilization(event):
              magic_per_distance = 50
              event['heavy_utilization'] = int(event['magicpoints'] >= (event['distance'] * magic_per_distance))
              return event

          def send_message_sqs(event):
              response = sqs.send_message(
                  QueueUrl=queue_url,
                  DelaySeconds=0,
                  MessageBody=json.dumps(event)
              )
              print(response['MessageId'])

          def event_format_check(event):
              event["latitude"] = float(event["latitude"])
              event["longitude"] = float(event["longitude"])
              return event

          def distance(lat1, lon1, lat2, lon2):
              p = 0.017453292519943295
              a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2
              return 12742 * asin(sqrt(a))

          def closest(listOfStations, target):
              return min(listOfStations,
                          key=lambda p: distance(target['latitude'],target['longitude'],p['latitude'],p['longitude']))

          def groundstations():
              return [{"id": "US1NYNY0074",  "latitude": 40.7969, "longitude": -73.9330, "elevation": 6.1},
                  {"id": "USW00014732",  "latitude": 40.7794, "longitude": -73.8803, "elevation": 3.4},
                  {"id": "USW00094728",  "latitude": 40.7789, "longitude": -73.9692, "elevation": 39.6},
                  {"id": "USW00094789",  "latitude": 40.6386, "longitude": -73.7622, "elevation": 3.4}]
      Description: Wild Rydes lambda function to look up nearest weather groundstation based on lat/long
      Handler: index.handler
      DeadLetterConfig:
        TargetArn: !GetAtt TransformAndMapDataFunctionDLQ.Arn
      MemorySize: 128
      Environment:
        Variables:
          OUTPUT_QUEUE: !Ref TransformedAndMappedDataQueue
      Role: !GetAtt DataProcessingExecutionRole.Arn
      Runtime: python3.7
      Timeout: 3
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  WriteTransformedDataToS3Function:
    Type: AWS::Lambda::Function
    Properties:
      Description: Wild Rydes lambda function to parse unicorn csv data and send downstream to lookup nearest groundstation
      Handler: index.handler
      DeadLetterConfig:
        TargetArn: !GetAtt WriteTransformedDataToS3FunctionDLQ.Arn
      MemorySize: 128
      Environment:
        Variables:
          OUTPUT_BUCKET: !Ref DataBucket
      Role: !GetAtt DataProcessingExecutionRole.Arn
      Runtime: python3.7
      Timeout: 3
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
      Code:
        ZipFile: |
          import boto3
          import json
          import os

          client = boto3.client('s3')
          bucket = os.environ['OUTPUT_BUCKET']

          def handler(event, context):
              print('## EVENT')
              print(event)
              for record in event['Records']:
                  json_event = json.loads(record['body'])
                  key = get_key_from_event_json(json_event)
                  body = get_body_from_event_json(json_event)
                  upload_file(body, key)
              return event

          def get_key_from_event_json(event):
              return 'processed/' + event["statustime"] + '.csv'

          def get_body_from_event_json(event):
              body = ",".join(event.keys()) + "\n"
              body = body + ",".join(map(str, event.values()))
              return body

          def upload_file(body, key):
              client.put_object(Body=body, Bucket=bucket, Key=key)

  LookUpNearestGroundstationEventSource:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: 10
      Enabled: True
      EventSourceArn: !GetAtt IngestedRawDataQueue.Arn
      FunctionName: !Ref TransformAndMapDataFunction

  ProcessedDataEventSource:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: 10
      Enabled: True
      EventSourceArn: !GetAtt TransformedAndMappedDataQueue.Arn
      FunctionName: !Ref WriteTransformedDataToS3Function
  #####
  # CloudWatch Dashboard
  #####
  CloudWatchDashboard:
    Type: "AWS::CloudWatch::Dashboard"
    Properties:
      DashboardName: "Wild_Rydes_Machine_Learning"
      DashboardBody: !Sub
        - |
            {
            	"widgets": [{
            		"type": "metric",
            		"x": 0,
            		"y": 0,
            		"width": 12,
            		"height": 12,
            		"properties": {
            			"metrics": [
            				["AWS/Lambda", "Invocations", "FunctionName", "${IngestUnicornRawDataFunction}"],
            				["...", "${WriteTransformedDataToS3Function}"],
            				["...", "${TransformAndMapDataFunction}"]
            			],
            			"view": "timeSeries",
            			"stacked": false,
            			"region": "us-east-1",
            			"stat": "Sum",
            			"period": 60
            		}
            	}, {
            		"type": "metric",
            		"x": 12,
            		"y": 0,
            		"width": 12,
            		"height": 6,
            		"properties": {
            			"metrics": [
            				["AWS/SQS", "NumberOfMessagesSent", "QueueName", "${IngestedRawDataQueue}"],
            				["...", "${TransformedAndMappedDataQueue}"]
            			],
            			"view": "timeSeries",
            			"stacked": false,
            			"region": "us-east-1",
            			"stat": "Sum",
            			"period": 300
            		}
            	}, {
            		"type": "metric",
            		"x": 12,
            		"y": 6,
            		"width": 12,
            		"height": 6,
            		"properties": {
            			"metrics": [
            				["AWS/SQS", "NumberOfEmptyReceives", "QueueName", "${IngestedRawDataQueue}"],
            				["...", "${TransformedAndMappedDataQueue}"]
            			],
            			"view": "timeSeries",
            			"stacked": false,
            			"region": "us-east-1",
            			"stat": "Sum",
            			"period": 300
            		}
            	}]
            }
        - { IngestUnicornRawDataFunction: !Ref IngestUnicornRawDataFunction, WriteTransformedDataToS3Function: !Ref WriteTransformedDataToS3Function, TransformAndMapDataFunction: !Ref TransformAndMapDataFunction, IngestedRawDataQueue: !GetAtt IngestedRawDataQueue.QueueName, TransformedAndMappedDataQueue: !GetAtt TransformedAndMappedDataQueue.QueueName }
Outputs:
  DataBucketName:
    Value: !Ref DataBucket
