AWSTemplateFormatVersion: 2010-09-09
Description: Wild Rydes machine learning infrastructure
Resources:
  DataBucket:
    Type: AWS::S3::Bucket
    DependsOn: IngestUnicornRawDataFunction
    Properties:
      BucketName: !Sub "${AWS::StackName}-databucket-${AWS::AccountId}"
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
      NotificationConfiguration:
        LambdaConfigurations:
          -
            Function: !GetAtt IngestUnicornRawDataFunction.Arn
            Event: "s3:ObjectCreated:*"
            Filter:
              S3Key:
                Rules:
                  -
                    Name: suffix
                    Value: json
  S3DataBucketInvokeLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref IngestUnicornRawDataFunction
      Principal: s3.amazonaws.com
      SourceArn: !Sub "arn:aws:s3:::${AWS::StackName}-databucket-${AWS::AccountId}"
  DataProcessingExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        -
          PolicyName: "AllowTransformedBucket"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "*"
                Resource: !Sub "arn:aws:s3:::${AWS::StackName}-databucket-${AWS::AccountId}"
        -
          PolicyName: "AllowTransformedBucketObjects"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "*"
                Resource: !Sub "arn:aws:s3:::${AWS::StackName}-databucket-${AWS::AccountId}/*"
        -
          PolicyName: "AllowNearestStationQueue"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "*"
                Resource: !GetAtt IngestedRawDataQueue.Arn
        -
          PolicyName: "AllowProcessedBucketQueue"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "*"
                Resource:
                  -
                    !GetAtt TransformedAndMappedDataQueue.Arn
                  -
                    !GetAtt TransformAndMapDataFunctionDLQ.Arn
                  -
                    !GetAtt IngestUnicornRawDataFunctionDLQ.Arn
                  -
                    !GetAtt WriteTransformedDataToS3FunctionDLQ.Arn
        -
          PolicyName: "AllowDLQs"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "*"
                Resource:
                  -
                    !GetAtt TransformAndMapDataFunctionDLQ.Arn
                  -
                    !GetAtt IngestUnicornRawDataFunctionDLQ.Arn
                  -
                    !GetAtt WriteTransformedDataToS3FunctionDLQ.Arn
        - PolicyName: "AllowLogging"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action: ['logs:*']
                Resource: 'arn:aws:logs:*:*:*'
  TransformAndMapDataFunctionDLQ:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  IngestUnicornRawDataFunctionDLQ:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  WriteTransformedDataToS3FunctionDLQ:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  IngestedRawDataQueue:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  TransformedAndMappedDataQueue:
    Type: "AWS::SQS::Queue"
    Properties:
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  WriteTransformedDataToS3Function:
    Type: AWS::Lambda::Function
    Properties:
      Description: Wild Rydes lambda function to parse unicorn csv data and send downstream to lookup nearest groundstation
      Handler: index.handler
      DeadLetterConfig:
        TargetArn: !GetAtt WriteTransformedDataToS3FunctionDLQ.Arn
      MemorySize: 128
      Environment:
        Variables:
          OUTPUT_BUCKET: !Ref DataBucket
      Role: !GetAtt DataProcessingExecutionRole.Arn
      Runtime: python3.7
      Timeout: 3
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
      Code:
        ZipFile: |
          import boto3
          import json
          import os

          client = boto3.client('s3')
          bucket = os.environ['OUTPUT_BUCKET']

          def handler(event, context):
              print('## EVENT')
              print(event)
              for record in event['Records']:
                  json_event = json.loads(record['body'])
                  key = get_key_from_event_json(json_event)
                  body = get_body_from_event_json(json_event)
                  upload_file(body, key)
              return event

          def get_key_from_event_json(event):
              return 'processed/' + event["statustime"] + '.csv'

          def get_body_from_event_json(event):
              body = ",".join(event.keys()) + "\n"
              body = body + ",".join(map(str, event.values()))
              return body

          def upload_file(body, key):
              client.put_object(Body=body, Bucket=bucket, Key=key)

  IngestUnicornRawDataFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import boto3
          import json
          import os

          client = boto3.client('s3')
          sqs = boto3.client('sqs')
          queue_url = os.environ['OUTPUT_QUEUE']

          def send_to_sqs(json_data):
            data = json_data
            if 'travel_data' in json_data:
              data = json_data['travel_data']

            for entry in data:
              lower_cased = {k.lower(): v for k, v in entry.items()}
              response = sqs.send_message(
                QueueUrl=queue_url,
                DelaySeconds=0,
                MessageBody=json.dumps(lower_cased)
              )
            print('all rows sent to sqs')

          def handler(event, context):
              for record in event['Records']:
                  bucket = record['s3']['bucket']['name']
                  key = record['s3']['object']['key']
                  content_object = client.get_object(Bucket=bucket, Key=key)
              file_content = content_object['Body'].read().decode('utf-8')
              json_content = json.loads(file_content)
              send_to_sqs(json_content)

      Description: Wild Rydes lambda function to parse unicorn JSON data and send downstream to lookup nearest groundstation
      Handler: index.handler
      DeadLetterConfig:
        TargetArn: !GetAtt IngestUnicornRawDataFunctionDLQ.Arn
      MemorySize: 256
      Environment:
        Variables:
          OUTPUT_QUEUE: !Ref IngestedRawDataQueue
      Role: !GetAtt DataProcessingExecutionRole.Arn
      Runtime: python3.7
      Timeout: 900
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
  TransformAndMapDataFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          from math import cos, asin, sqrt
          import boto3
          import json
          import os

          sqs = boto3.client('sqs')
          queue_url = os.environ['OUTPUT_QUEUE']

          def handler(event, context):
              print('## EVENT')
              print(event)
              for record in event['Records']:
                  json_event = json.loads(record['body'])
                  json_event = event_format_check(json_event)
                  json_event["groundstation"] = closest(groundstations(),
                                                      {"latitude": json_event["latitude"], "longitude": json_event["longitude" ]})["id"]
                  json_event = label_heavy_magic_utilization(json_event)
                  send_message_sqs(json_event)
              return event

          def label_heavy_magic_utilization(event):
              magic_per_distance = 50
              event['heavy_utilization'] = int(event['magicpoints'] >= (event['distance'] * magic_per_distance))
              return event

          def send_message_sqs(event):
              response = sqs.send_message(
                  QueueUrl=queue_url,
                  DelaySeconds=0,
                  MessageBody=json.dumps(event)
              )
              print(response['MessageId'])

          def event_format_check(event):
              event["latitude"] = float(event["latitude"])
              event["longitude"] = float(event["longitude"])
              return event

          def distance(lat1, lon1, lat2, lon2):
              p = 0.017453292519943295
              a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2
              return 12742 * asin(sqrt(a))

          def closest(listOfStations, target):
              return min(listOfStations,
                          key=lambda p: distance(target['latitude'],target['longitude'],p['latitude'],p['longitude']))

          def groundstations():
              return [{"id": "US1NYNY0074",  "latitude": 40.7969, "longitude": -73.9330, "elevation": 6.1},
                  {"id": "USW00014732",  "latitude": 40.7794, "longitude": -73.8803, "elevation": 3.4},
                  {"id": "USW00094728",  "latitude": 40.7789, "longitude": -73.9692, "elevation": 39.6},
                  {"id": "USW00094789",  "latitude": 40.6386, "longitude": -73.7622, "elevation": 3.4}]
      Description: Wild Rydes lambda function to look up nearest weather groundstation based on lat/long
      Handler: index.handler
      DeadLetterConfig:
        TargetArn: !GetAtt TransformAndMapDataFunctionDLQ.Arn
      MemorySize: 128
      Environment:
        Variables:
          OUTPUT_QUEUE: !Ref TransformedAndMappedDataQueue
      Role: !GetAtt DataProcessingExecutionRole.Arn
      Runtime: python3.7
      Timeout: 3
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning

  LookUpNearestGroundstationEventSource:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: 10
      Enabled: True
      EventSourceArn: !GetAtt IngestedRawDataQueue.Arn
      FunctionName: !Ref TransformAndMapDataFunction

  ProcessedDataEventSource:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: 10
      Enabled: True
      EventSourceArn: !GetAtt TransformedAndMappedDataQueue.Arn
      FunctionName: !Ref WriteTransformedDataToS3Function
  #####
  # NY Ground Station resources
  #####
  WildRydesMLGlueDatabase:
    Type: AWS::Glue::Database
    Properties:
      DatabaseInput:
        Name: !Sub "wildrydesmlgluedatabase-${AWS::StackName}"
        Description: "Glue DB for Wild Rydes ML workshop"
      CatalogId: !Ref AWS::AccountId
  WildRydesMLGlueTable:
    Type: AWS::Glue::Table
    Properties:
      DatabaseName: !Ref WildRydesMLGlueDatabase
      CatalogId: !Ref AWS::AccountId
      TableInput:
        Name: !Sub "externalweatherdatacsvtable-${AWS::StackName}"
        Parameters: { "classification" : "csv" }
        TableType: "EXTERNAL_TABLE"
        StorageDescriptor:
          Location:
            Fn::Sub: "s3://noaa-ghcn-pds/csv/"
          InputFormat: "org.apache.hadoop.mapred.TextInputFormat"
          OutputFormat: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          SerdeInfo:
            Parameters: { "separatorChar" : ",", "field.delim": "," }
            SerializationLibrary: "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe"
          StoredAsSubDirectories: false
          Columns:
            - Name: id
              Type: string
            - Name: year_date
              Type: string
            - Name: element
              Type: string
            - Name: data_value
              Type: string
            - Name: m_flag
              Type: string
            - Name: q_flag
              Type: string
            - Name: s_flag
              Type: string
            - Name: obs_time
              Type: string
  #####
  # Data prep/Machine Learning resources
  #####
  SageMakerExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /service-role/
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - sagemaker.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
        - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
      MaxSessionDuration: 3600
      Policies:
        -
          PolicyName: AllowIAMGetRole
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "iam:GetRole"
                Resource: "*"
        -
          PolicyName: AllowSageMakerCreateTrainingJob
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sagemaker:CreateTrainingJob"
                Resource: "*"
  WildRydesNotebook:
    Type: AWS::SageMaker::NotebookInstance
    Properties:
      InstanceType: ml.t3.xlarge
      RoleArn: !GetAtt SageMakerExecutionRole.Arn
      DirectInternetAccess: Enabled
      VolumeSizeInGB: 5
      RootAccess: Enabled
  #####
  # Inference resources
  #####
  ModelInferenceFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Wild Rydes lambda function make model inferences
      Handler: index.handler
      MemorySize: 128
      Role: !GetAtt DataProcessingExecutionRole.Arn
      Runtime: python2.7
      Environment:
        Variables:
          OUTPUT_BUCKET: !Ref DataBucket
          MODEL_PATH: 'linear-learner-yyyy-mm-dd-00-40-46-627/output/model.tar.gz'
      Timeout: 3
      Tags:
        -
          Key: Workshop
          Value: Wild Rydes
        -
          Key: Module
          Value: Machine Learning
      Code:
        S3Bucket: central-multicustomer-aws-immersion-days
        S3Key: wild-rydes-ml-lab/inferencefunction.zip
  ApiGateway:
    Type: "AWS::ApiGateway::RestApi"
    Properties:
      Name: "ModelInferenceApi"
      Description: "Wild Rydes Model Inference REST API"
  ApiGatewayRootMethod:
    Type: "AWS::ApiGateway::Method"
    Properties:
      AuthorizationType: "NONE"
      HttpMethod: "POST"
      Integration:
        IntegrationHttpMethod: "POST"
        Type: "AWS_PROXY"
        Uri: !Sub
          - "arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${lambdaArn}/invocations"
          - lambdaArn: !GetAtt "ModelInferenceFunction.Arn"
      ResourceId: !GetAtt "ApiGateway.RootResourceId"
      RestApiId: !Ref "ApiGateway"
  lambdaApiGatewayInvoke:
    Type: "AWS::Lambda::Permission"
    Properties:
      Action: "lambda:InvokeFunction"
      FunctionName: !GetAtt "ModelInferenceFunction.Arn"
      Principal: "apigateway.amazonaws.com"
      SourceArn: !Sub "arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${ApiGateway}/*/POST/"
  apiGatewayDeployment:
    Type: "AWS::ApiGateway::Deployment"
    DependsOn:
      - "ApiGatewayRootMethod"
    Properties:
      RestApiId: !Ref "ApiGateway"
      StageName: "prod"
  #####
  # CloudWatch Dashboard
  #####
  CloudWatchDashboard:
    Type: "AWS::CloudWatch::Dashboard"
    Properties:
      DashboardName: "Wild_Rydes_Machine_Learning"
      DashboardBody: !Sub
        - |
            {
            	"widgets": [{
            		"type": "metric",
            		"x": 0,
            		"y": 0,
            		"width": 12,
            		"height": 12,
            		"properties": {
            			"metrics": [
            				["AWS/Lambda", "Invocations", "FunctionName", "${IngestUnicornRawDataFunction}"],
            				["...", "${WriteTransformedDataToS3Function}"],
            				["...", "${TransformAndMapDataFunction}"]
            			],
            			"view": "timeSeries",
            			"stacked": false,
            			"region": "us-east-1",
            			"stat": "Sum",
            			"period": 60
            		}
            	}, {
            		"type": "metric",
            		"x": 12,
            		"y": 0,
            		"width": 12,
            		"height": 6,
            		"properties": {
            			"metrics": [
            				["AWS/SQS", "NumberOfMessagesSent", "QueueName", "${IngestedRawDataQueue}"],
            				["...", "${TransformedAndMappedDataQueue}"]
            			],
            			"view": "timeSeries",
            			"stacked": false,
            			"region": "us-east-1",
            			"stat": "Sum",
            			"period": 300
            		}
            	}, {
            		"type": "metric",
            		"x": 12,
            		"y": 6,
            		"width": 12,
            		"height": 6,
            		"properties": {
            			"metrics": [
            				["AWS/SQS", "NumberOfEmptyReceives", "QueueName", "${IngestedRawDataQueue}"],
            				["...", "${TransformedAndMappedDataQueue}"]
            			],
            			"view": "timeSeries",
            			"stacked": false,
            			"region": "us-east-1",
            			"stat": "Sum",
            			"period": 300
            		}
            	}]
            }
        - { IngestUnicornRawDataFunction: !Ref IngestUnicornRawDataFunction, WriteTransformedDataToS3Function: !Ref WriteTransformedDataToS3Function, TransformAndMapDataFunction: !Ref TransformAndMapDataFunction, IngestedRawDataQueue: !GetAtt IngestedRawDataQueue.QueueName, TransformedAndMappedDataQueue: !GetAtt TransformedAndMappedDataQueue.QueueName }
Outputs:
  AthenaSelectQuery:
    Value: !Sub |
      SELECT * FROM "${WildRydesMLGlueDatabase}"."${WildRydesMLGlueTable}" WHERE q_flag = '' AND id IN ('US1NYNY0074', 'USC00305798', 'USC00305799', 'USC00305804', 'USC00305806', 'USC00305816', 'USW00014732', 'USW00014786', 'USW00093732', 'USW00094728', 'USW00094789');
  AthenaCSVLocation:
    Value: !Sub |
      https://s3.console.aws.amazon.com/s3/buckets/aws-athena-query-results-${AWS::AccountId}-${AWS::Region}/Unsaved/?region=${AWS::Region}&tab=overview
  DataBucketName:
    Value: !Ref DataBucket
  ApiGatewayInvokeURL:
    Value: !Sub "https://${ApiGateway}.execute-api.${AWS::Region}.amazonaws.com/prod"
  InferenceFunctionTestCommand:
    Description: "cURL command to invoke our lambda function to make inferences"
    Value:
      Fn::Join:
        - " "
        -
          - "curl -d '{ \"distance\": 1, \"healthpoints\": 100, \"magicpoints\": 200, \"TMAX\": 1, \"TMIN\": 1, \"PRCP\": 100 }' -H \"Content-Type: application/json\" -X POST"
          - !Sub "https://${ApiGateway}.execute-api.${AWS::Region}.amazonaws.com/prod"
